---
title: "Zeespiegelmonitor analyse"
author: "Willem Stolte, Nathalie Dees"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document: null
  html_document:
    df_print: paged
    code_folding: hide
    outputdir: ../../docs
  pdf_document: default
always_allow_html: true
params:
  monitoryear: 2025
  startyear: 1890
  wind_or_surge_type: GTSM
  overwrite: FALSE
  station:
  - Delfzijl
  - Harlingen
  - Den Helder
  - IJmuiden
  - Hoek van Holland
  - Vlissingen
  - Netherlands
  - Netherlands (without Delfzijl)
  modeltype:
  - linear
  - broken_linear
  - broken_squared
---

# Sea Level Monitor analysis

The Sea Level Monitor methodology is described in detail in Deltares (2023). Principles are:

-   Sea Level is based on yearly averaged sea levels that are reported by Rijkswaterstaat to [PSMSL](https://www.psmsl.org) for the six main stations.
-   The mean of these stations is used to estimate the "current sea-level rise". The measurements since 1890 are taken into account. Measurements before that are considered less valid because the Amsterdam Ordnance Datum was not yet normalized.
-   Sea Level is corrected for yearly fluctuations in *surge* using independently modelled surge values from the Global Surge and Tide Model (GTSM).
-   The trend of Sea Level over the years is fitted with various models including nodal tide, with anD without an acceleration term. For the models with accelleration terms, the significance of the accelleration is tested.
-   From the different models a preferred model is chosen based on:
    -   lowest AIC (Akaike Information Criteria)
    -   significant better fit than the simplest model (linear model)
    
```{r setup, include=FALSE}

knitr::opts_chunk$set(
  echo = TRUE,
  comment=FALSE,
  message=FALSE,
  warning = FALSE
)

require(leaflet)
require(plotly)
require(nlme)
require(tidyverse)
# require(reticulate)

config <- RcppTOML::parseToml("_common/configuration.TOML")
config_flat <- list_flatten(config)
source("_common/functions.R")
source("_common/plotfunctions.R")
epoch = config$constants$epoch
mainstations_df <- readMainStationInfo(filepath = "../../")
mainstations_locs <- readMainStationLocations(path = "../../")
nstations = length(params$station)
nmodels  = length(params$modeltype)
nsurge  = length(params$wind_or_surge_type)
select = dplyr::select

```


This document is executed with the following parameters:

```{r}

data.frame(
  "name" = names(unlist(params)),
  "value" = unlist(params),
  row.names = NULL
  ) %>%
  knitr::kable(caption = "Values of document parameters")

```









## Get latest data from file

In an other script, annual average sea level data for the Dutch main stations is downloaded from the [Permanent Service for Mean Sea Level site](http://www.psmsl.org) and combined with the Global Tide and Surge Model (GTSM) annual average surge values. 

```{r}

current_df <-   read_csv2("../../data/deltares/results/dutch-sea-level-monitor-export-stations-latest.csv") %>%
  filter(year >= params$startyear)

```

In this analysis, measurements over the period `r params$startyear` to `r params$monitoryear - 1` are considered.

## Locations of the main stations

This document analyses the sea level trend of the main stations in the Netherlands using different models. Based on geographical coverage and available time series length six stations are considered to be "main tide gauge stations".

Additionally, to calculate the average sea level and sea level trend along the Dutch Coast, the main station sea level is averaged for each year (virtual station "Netherlands"). Because the station "Delfzijl" has a considerable gap in vertical adjustment for subsidence, we also consider a variant in which Delfzijl is omitted from the main analysis selection ("Netherlands (without Delfzijl)").

```{r selected-stations, fig.cap="Hoofdgetijstations in Nederland. Er is aangegeven welke stations zijn meegenomen in dit rekendocument. "}

map_stations(df = current_df, mainstations_df = mainstations_df, mainstations_locs = mainstations_locs)

```

### Sea level measurements

In this section we look at sea level measurements. The global collection of tide gauge records at the PSMSL was used to access the data. There are two types of datasets the "Revised Local Reference" and "Metric". For the Netherlands the difference is that the "Revised Local Reference" undoes the corrections from the NAP correction in 2005, to get a consistent dataset. Here we transform the RLR back to NAP (without undoing the correction).

The rlrnap computes the rlr back to latest NAP (ignoring the undoing of the NAP correction). Id's are the station ids in the PSMSL dataset. They may change from year to year as the PSMSL 0 point is arbitary. You can lookup the relevant parameters in the schematic diagram like this [LRL diagram for station Vlissingen](https://www.psmsl.org/data/obtaining/rlr.diagrams/20.php)


```{r}
knitr::kable(mainstations_df[,c('name', 'psmsl_id', 'msl-rlr', 'msl-nap', 'nap-rlr')], caption = "PSMSL information on the six mains tide gauge stations in the Netherlands.")
```

Sea level data for all six main station are shown below in an interactive plot.

```{r zeespiegelmetingen, fig.width=8, fig.height=8, fig.cap="De gemiddelde jaarlijkse zeespiegel voor de zes hoofdstations langs de Nederlandse kust."}

p <- current_df %>%
  dplyr::filter(!grepl("Netherlands", station)) %>%
ggplot(aes(year, height)) +
  geom_point(alpha = 1, aes(color = station), shape = 21, fill = "white", size = 1) +
  geom_line(alpha = 0.5, aes(color = station), linewidth = 0.5) +
  xlab("jaar") + ylab("gemeten zeespiegel in mm") +
  theme_light() +
  theme(legend.position = "bottom")

ggplotly(p) %>% layout(legend = list(x = 0.05, y = 0.95))

```


Sea level measurements for the six main stations (yearly average) are shown in figure \@ref(fig:zeespiegelmetingen) as deviations from the mean for each year. This way, the characteristic patterns of the stations are easier to see. 

A few things become clear

- Harlingen show a negative trend as compared to the average of the stations from roughly 1930 to 1990. There is a sudden "bump" around 1970. 
- IJmuiden shows strong fluctuations in the first decades of the series. in 2018, the signal drops a few cm. 


```{r zeespiegelanomalieen, fig.width=8, fig.height=8, fig.cap="Afwijking van het gemiddelde voor elk jaar voor de zes hoofdstations langs de Nederlandse kust."}

current_df %>%
  dplyr::filter(!grepl("Netherlands", station)) %>%
  group_by(year) %>%
  mutate(mean = mean(height)) %>% ungroup() %>%
  mutate(norm_station_height = height - mean) %>%
  ggplot(aes(year, norm_station_height, color = station)) +
  geom_point(alpha = 0.5) +
  geom_line(alpha = 0.2) +
  facet_wrap(facets = "station", ncol = 2) +
  theme(legend.position = "bottom")

# p
```

```{r zeespiegelmetingenGemiddeld, fig.width=8, fig.height=5, fig.cap="Jaarlijks gemiddelde zeespiegel voor gemiddelde van stations langs de Nederlandse kust."}
p <- current_df %>%
  dplyr::filter(grepl("Netherlands", station)) %>%
ggplot(aes(year, height)) +
  geom_point(alpha = 1, aes(color = station), shape = 21, fill = "white", size = 1) +
  geom_line(alpha = 0.5, aes(color = station), linewidth = 0.75) +
  xlab("jaar") + ylab("gemeten zeespiegel in mm") +
  theme_light() +
  theme(legend.position = "bottom")

ggplotly(p) %>% layout(legend = list(x = 0.05, y = 0.95))
# p
```

### Sea level high years

The 5 years with highest sea levels are shown in table \@ref(tab:highest5years). 


```{r highest5years}

current_df %>%
  dplyr::filter(station == "Netherlands (without Delfzijl)") %>%
  dplyr::arrange(-height) %>%
  dplyr::select(year, station, height_mm = height) %>%
  # dplyr::group_by(station) %>%
  dplyr::slice(c(1:5)) %>%
  knitr::kable(caption = "Overview of the five highest yearly average water levels for the combined station Netherlands (without Delfzijl) in mm during the considered period. ")
```



### Storm surge

The expected storm surge per year is determined using output of the Global Tide and Surge Model (GTSM) (ref). This calculates the surge given the bathymetry and climatic conditions. Model results are available from 1950 onwards (figure \@ref(fig:gtsm-surge)). The model is run each successive year to calculate the annual average wind and air pressure for use in the Sea Level Monitor. The calculated variation in surge (surge anomaly) is subtracted from the measured sea level before the sea level rise is calculated. For the years before 1950, no runs are available and sea level is corrected for average surge only. This correction reduces the variation due to differences in surge per year and allows a more precise estimate of the long-term trend to be made.

```{r gtsm-surge-anomalie, fig.width=8, fig.height=5, fig.cap="Modelled surge anomaly (deviation of storm surge from long year avearge). The yearly averages surge is calculated for 1950 - now. For earlier years, an average surge is assumed." }

p <- current_df %>%
  # filter(!grepl("Netherlands", station)) %>%
  # filter(station == "IJmuiden") %>%
ggplot(aes(year, surge_anomaly)) +
  geom_point(alpha = 1, aes(color = station), shape = 21, fill = "white", size = 1) +
  geom_line(alpha = 0.5, aes(color = station), linewidth = 0.75) +
  xlab("jaar") + ylab("windopzet in mm") +
  theme_light() +
  theme(legend.position = "bottom") +
  coord_cartesian(xlim = c(1945, params$monitoryear))

ggplotly(p) # %>% layout(legend = list(x = 0.05, y = 0.95))
# p
```


## Trend analysis

The sea level trend is calculated using generalized linear regression. the following models are tested (Deltares 2018 and Deltares 2023):

-   linear model
-   broken linear model (with breakpoint at 1993)
-   broken quadratic model (breakpoint at 1960)

The trend is calculated for all stations individually, for the mean of all stations ("Netherlands"), and for means of all stations minus station Delfzijl ("Netherlands without Delfzijl"). 

In the regression equation, nodal tide is one of the components and is estimated as a sinusoid curve with a period of 18.6 years. 

```{r nest-per-station}
byStation <- current_df %>%
  filter(year > params$startyear) %>%
  dplyr::group_by(station) %>%
  tidyr::nest() %>%
  dplyr::ungroup()
```

```{r}

selectedmodel <- params$modeltype

models <- byStation %>%
  expand_grid(modeltype = selectedmodel) %>%

  mutate(modelfunctionname = paste(modeltype, "model", sep = "_")) %>%
  # add functions for model calculation
  mutate(modelfunctions = map(modelfunctionname, get)) %>%
  # add models based on data and functions
  mutate(model = pmap(
    list(
      data,
      modelfunctions
    ),
    \(.d, .f) .f(.d)
  )) %>%
  mutate(
    glance = map(model, broom::glance),
    rsq    = glance %>% map_dbl("r.squared"),
    adj.rsq = glance %>% map_dbl("adj.r.squared"),
    AIC    = glance %>% map_dbl("AIC"),
    tidy   = map(model, broom::tidy),
    augment = map(model, broom::augment),
    equation = map(model, function(x) equatiomatic::extract_eq(x, ital_vars = TRUE))
  )

```


```{r, results="asis"}
eq <- models %>% 
  distinct(modeltype, equation) %>%
  mutate(equation = paste0("$`", equation, "`$"))

knitr::kable(eq, escape = F)

```



## Autocorrelation

Autocorrelation with previous year(s) can sometimes explain part of the otherwise unexplained variance. Especially when a trend is detected in the data, autocorrelation with relatively short lags (1 or few years) often occurs. In case of autocorrelation, we recalculate standard errors of the estimated parameters accordingly.

```{r acf-plot, fig.height=nstations*1.5+1, fig.width=nmodels*3+1, fig.cap="Autocorrelation plot for selected stations and models. "}

plot_ACF(models)

```

There appears to be a consistent autocorrelation for all stations and models with a 'lag' of one year. The autocorrelation does not influence the value of the calculated trend parameters, but needs to be taken into account when calculating standard errors. The [Newey West autocorrelatie term](https://search.r-project.org/CRAN/refmans/sandwich/html/NeweyWest.html) is used to correctly calculate the standard errors.

At station 'Vlissingen' there is autocorrelation with a 'lag' of 10 years. This could indicate an effect of the 8.8 year 'lunar perigee cycle'. Because this only occurs at Vlissingen, this tidal component is not further accounted for in the analysis. 

There is no apparent autocorrelation with a 'lag' of 18.6 years, the 'nodal tide' cycle. This is because the nodal tide is already incorporated in the three models. 


```{r add-HAC}

require(sandwich)

models <- addHACterms(models)

```

## Heteroskedasticity

### Residuals distribution

The distribution of residuals resembles a normal distribution for most stations and model variants. Station Harlingen is an example where the distribution is out of centre when using the linear model. The width of the residuals distribution is narrower when measurements are corrected for surge prior to application of the models.

```{r, fig.height=nstations*1.5+1, fig.width=nmodels*3+1, out.width="100%"}


plotResidualDistribution(models)


```

### Variation of residuals over time

Distribution of residuals should not reveal a clear deviation from a horizontal line.

```{r, fig.height=nstations*1.5+1, fig.width=nmodels*3+1}
models %>%
  unnest(c(data, augment), names_sep = "_") %>%
  ggplot(aes(data_year, augment_.resid)) +
  geom_point(alpha = 0.4) +
  facet_grid(station ~ modeltype) +
  theme(strip.text.y = element_text(angle = 0))
```

## Sea level rise

```{r}

lookup <- c(
  Constant = "(Intercept)",
  Trend = "I(year - epoch)",
  u_nodal = "I(cos(2 * pi * (year - epoch)/(18.613)))",
  v_nodal = "I(sin(2 * pi * (year - epoch)/(18.613)))",
  `+ trend 1993` = "from1993",
  `+ square_trend 1960` = "from1960_square",
  AR_term = "previousYearHeight"
)

all_predictions <- makePredictionTable(models, lookup)

if(params$overwrite){
  write_csv(all_predictions, file = paste0("../../results/analysis_output/predictions_", today(), ".csv"))
  write_csv(all_predictions, file = "../../results/analysis_output/predictions_latest.csv")
}
```

```{r prediction-plot, eval=T, fig.height=nstations*1.3+1, fig.width=nmodels*3+1, fig.cap= "Observed and predicted sea level for selected stations and models. "}

ggplot(
  all_predictions,
  aes(x = data_year)
) +
  geom_point(aes(y = data_height, color = "observed"), alpha = 0.5, size = 1) +
  geom_line(aes(y = prediction_recalc, color = "predicted"), linewidth = 1) +
  facet_grid(station ~ modeltype) +
  theme(strip.text.y = element_text(angle = 0))

```

```{r, eval=FALSE, fig.height=nstations*2+2, fig.width=nmodels*2+2}

  p <- plot_station( 
    predictions_all = all_predictions,
    stationi = unique(all_predictions$station),
    correctionVariant = "GTSM", 
    modelVariant = unique(all_predictions$modeltype), 
    printNumbers = F, 
    startyear = 1890
  ) +
  facet_grid(station ~ modeltype) +
  theme(
    # legend.direction = "horizontal",
    # legend.box = "horizontal",
    legend.position = "bottom", #c(0.975, 0.025),
    # legend.justification = c(1, 0),
    legend.title = element_blank()
  ) +
  theme(strip.text.y = element_text(angle = 90)) 

  
  # ggplotly(p) %>% layout(legend = list(x = 0.05, y = 0.95))
  p
```



## Parameters

```{r}

## gebruik DT in plaats van kableextra
# library(DT)

lookup.df <- data.frame(long_term = unname(lookup),
                        short_term = names(lookup))

parametertable <- models %>%
  select(station, modeltype, tidy) %>% 
  unnest(tidy) %>%
  left_join(models %>%
              select(station, modeltype, tidy.HAC) %>%
              unnest(tidy.HAC),
            by = c(
              station = "station",
              modeltype = "modeltype",
              term = "term.HAC"
            )
  ) %>%
  mutate(across(where(is.numeric), round, 3)) %>%
  left_join(lookup.df, by = c(term = "long_term")) %>%
  select(-term, term = short_term) %>%
  relocate(term, .after = modeltype)

# parametertable %>%
#   DT::datatable(
#     options = list(
#       "digits" = 3
#     )
#   )

if(params$overwrite){
  write_csv(parametertable, file = paste0("../../results/analysis_output/parameters_", today(), ".csv"))
  write_csv(parametertable, file = "../../results/analysis_output/parameters_latest.csv")
}
  kableExtra::kable(parametertable,
    caption = "Coefficients for all models and stations.",digits = 2
    ) %>%
  kableExtra::scroll_box(height = "500px")

```

## Which model is the preferred model?

### Is there a significant acceleration?

```{r}
acc_broken_linear <- parametertable %>%
  filter(modeltype == "broken_linear") %>%
  filter(term == "+ trend 1993") %>%
  select(station, estimate, p.value )
knitr::kable(acc_broken_linear, caption = "p-values for the acceleration term in the broken linear model for all stations. ")
```

For the broken linear model, there is a significant acceleration starting in the year 1993 when fitting the average sea level combined for all stations without Delfzijl. For individual stations, the acceleration is not significant for the station IJmuiden.

```{r}
acc_broken_squared <- parametertable %>%
  filter(modeltype == "broken_squared") %>%
  filter(term == "+ square_trend 1960") %>%
  select(station, p.value )
knitr::kable(acc_broken_squared, caption = "p-values for the acceleration term in the broken squared model for all stations. ")
```

For the broken squared model, there is a significant acceleration starting in the year 1960 when fitting the average sea level combined for all stations without Delfzijl. For individual stations, the acceleration is not significant for the stations Vlissingen and IJmuiden.

### Which model has the lowest Akaike Information Criterion (AIC)?

Of the two models with an acceleration term, the model with lowest AIC is the preferred model.

```{r}
colors <- c(lowest = "orange")

AIC_df <- models %>%
  mutate(station = as.character(station)) %>%
  select(station, modeltype, AIC) %>%
  arrange(-AIC) %>% 
  mutate(modeltype = factor(modeltype, levels=config$runparameters$modeltype)) %>%
  mutate(station = factor(station, levels=config$runparameters$station)) %>%
  group_by(station) %>%
  mutate(AIC_score = ifelse(AIC == min(AIC), "lowest", ""))

AIC_df %>%
  ggplot(aes(x = modeltype, y = AIC, color = AIC_score)) +
  geom_point(size = 6, shape = "|") +
  coord_flip() +
  scale_color_manual(values = colors) +
  facet_wrap("station")
```

!!!!!! Automate and change

```{r}

linModStations <- AIC_df %>% filter(AIC_score == "lowest") %>% arrange(modeltype) %>% select(station, `lowest AIC model` = modeltype)

```


For the combined stations Netherlands and Netherlands (without Delfzijl), the broken-linear model has the lowest AIC, and is therefore the first candidate for the preferred model. In the next section, it is tested whether the broken-linear model explains the observed variation significantly better than the simplest model, the linear model.

For stations Den Helder and Hoek van Holland, the broken squared model is the model with lowest AIC.

At station IJmuiden, all three models have similar AIC.

Considering all stations, the broken linear and the broken squared model describe the observed variation approximately equally well.

### Is the preferred model significantly better than the linear model?

The broken linear model is chosen as the preferred candidate because it gave a better explanation of the observation, corrected for the degrees of freedom of the model (AIC criterion). Here, it is tested whether the broken linear model is *significantly* better model that the most simple model, the broken linear model.  

```{r}
# extract models to compare
bl <- models %>% 
  filter(
    station == "Netherlands (without Delfzijl)",
    modeltype == "broken_linear"
  ) %>%
  select(model) %>% unlist(recursive = F) %>% unname()

l <- models %>% 
  filter(
    station == "Netherlands (without Delfzijl)",
    modeltype == "linear"
  ) %>%
  select(model) %>% unlist(recursive = F) %>% unname()

# create anova table
t <- anova(l[[1]], bl[[1]])
# extract p value from table
p_value <- t$`Pr(>F)`[2]

if(p_value<0.01) {
  alternativemodelaccepted = TRUE
  alternativemodelrefused = FALSE
}
```

The Anova table for model comparison is shown below.

```{r, results='asis'}

# makePrettyAnovaTable(t, 3)

print(t)

```

The acceleration model (broken linear) has one more degree of freedom than the linear model. The broken linear model is significantly better than the linear model (p \< 0.001).

## Conclusions

Based on the above analysis, the following conclusions are drawn:

```{r conditional_block, echo=FALSE, results='asis', eval=alternativemodelaccepted}

cat('Based on variance analysis the broken linear model is significantly better than the linear model. the broken linear model is accepted as the preferred model.')

```

```{r , echo = FALSE, results = 'asis', eval=alternativemodelrefused}

cat('Based on variance analysis the broken linear model is not significantly better than the linear model. the linear model is accepted as the preferred model. ')

```
